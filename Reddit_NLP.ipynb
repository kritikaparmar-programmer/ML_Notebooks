{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reddit_NLP",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMLermnEasmAyp8D8x/apa0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kritikaparmar-programmer/ML_Projects/blob/main/Reddit_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tHAPRKesyTV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b0a99324-fab7-4bcb-b87c-fdd5a0af1406"
      },
      "source": [
        "# Data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Data visualisation\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Statistical libraries\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "# NLP\n",
        "import nltk\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Ml\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Performance Evaluation and Support\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "St54UaXCsz3g"
      },
      "source": [
        "data = pd.read_csv('/content/sample_data/data_reddit_india.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxhJl_krtLHW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "5f418ed6-d870-4195-8afb-fd1072cc4af1"
      },
      "source": [
        "# Data Shuffling\n",
        "data.drop(['Unnamed: 0'], inplace=True, axis=1)\n",
        "data[:] = data.sample(frac=1).values\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Score</th>\n",
              "      <th>ID</th>\n",
              "      <th>URL</th>\n",
              "      <th>num_comments</th>\n",
              "      <th>created_on</th>\n",
              "      <th>Body</th>\n",
              "      <th>Original</th>\n",
              "      <th>Flair</th>\n",
              "      <th>Comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I finally convinced him. That awesome moment w...</td>\n",
              "      <td>1892</td>\n",
              "      <td>d0em6s</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/d0em6s...</td>\n",
              "      <td>184</td>\n",
              "      <td>1.567793e+09</td>\n",
              "      <td>A little long story.  I am going through a lot...</td>\n",
              "      <td>False</td>\n",
              "      <td>[R]eddiquette</td>\n",
              "      <td>Larke ko ias officer banao....kudos to you op.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mumbai's high Covid count due to aggressive te...</td>\n",
              "      <td>258</td>\n",
              "      <td>g5wv53</td>\n",
              "      <td>https://theprint.in/theprint-otc/mumbais-high-...</td>\n",
              "      <td>37</td>\n",
              "      <td>1.587570e+09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>Policy/Economy</td>\n",
              "      <td>&gt; high Covid count due to aggressive testing\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@KeralaTourism: Tender chunks of beef, slow-ro...</td>\n",
              "      <td>385</td>\n",
              "      <td>ep32la</td>\n",
              "      <td>https://twitter.com/KeralaTourism/status/12174...</td>\n",
              "      <td>63</td>\n",
              "      <td>1.579128e+09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>Food</td>\n",
              "      <td>[removed]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Music from the string quartet that raised the ...</td>\n",
              "      <td>17</td>\n",
              "      <td>g1l3p3</td>\n",
              "      <td>https://www-thehindu-com.cdn.ampproject.org/v/...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.586954e+09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>Sports</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I am Ashish K. Mishra, I write stories. AMA</td>\n",
              "      <td>76</td>\n",
              "      <td>76xx01</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/76xx01...</td>\n",
              "      <td>212</td>\n",
              "      <td>1.508269e+09</td>\n",
              "      <td>I am the Managing Editor of The Ken. We write ...</td>\n",
              "      <td>False</td>\n",
              "      <td>AMA</td>\n",
              "      <td>Would you rather reverse one decision you make...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Title  ...                                           Comments\n",
              "0  I finally convinced him. That awesome moment w...  ...    Larke ko ias officer banao....kudos to you op. \n",
              "1  Mumbai's high Covid count due to aggressive te...  ...  > high Covid count due to aggressive testing\\n...\n",
              "2  @KeralaTourism: Tender chunks of beef, slow-ro...  ...                                         [removed] \n",
              "3  Music from the string quartet that raised the ...  ...                                                NaN\n",
              "4        I am Ashish K. Mishra, I write stories. AMA  ...  Would you rather reverse one decision you make...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5r-TucqtPAH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "cdaacb7a-7e89-44b0-abb9-0feaa3d7df53"
      },
      "source": [
        "# Display data types and null values\n",
        "data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1650 entries, 0 to 1649\n",
            "Data columns (total 10 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Title         1650 non-null   object \n",
            " 1   Score         1650 non-null   int64  \n",
            " 2   ID            1650 non-null   object \n",
            " 3   URL           1650 non-null   object \n",
            " 4   num_comments  1650 non-null   int64  \n",
            " 5   created_on    1650 non-null   float64\n",
            " 6   Body          635 non-null    object \n",
            " 7   Original      1650 non-null   bool   \n",
            " 8   Flair         1650 non-null   object \n",
            " 9   Comments      1557 non-null   object \n",
            "dtypes: bool(1), float64(1), int64(2), object(6)\n",
            "memory usage: 117.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6WY2fgStVh1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ad9d307e-d02e-44ce-dd5a-f06218d2a28f"
      },
      "source": [
        "print(len(data['Flair'].unique()))\n",
        "data['Flair'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['[R]eddiquette', 'Policy/Economy', 'Food', 'Sports', 'AMA',\n",
              "       'Business/Finance', 'Photography', 'Science/Technology',\n",
              "       'AskIndia', 'Non-Political', 'Politics'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf-g0gimtmHN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "76030197-901a-4137-ffdb-e3de531abadb"
      },
      "source": [
        "# List of relevant features\n",
        "features = ['Flair', 'URL', 'Title', 'Comments', 'Body']\n",
        "data = data[features]\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Flair</th>\n",
              "      <th>URL</th>\n",
              "      <th>Title</th>\n",
              "      <th>Comments</th>\n",
              "      <th>Body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[R]eddiquette</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/d0em6s...</td>\n",
              "      <td>I finally convinced him. That awesome moment w...</td>\n",
              "      <td>Larke ko ias officer banao....kudos to you op.</td>\n",
              "      <td>A little long story.  I am going through a lot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Policy/Economy</td>\n",
              "      <td>https://theprint.in/theprint-otc/mumbais-high-...</td>\n",
              "      <td>Mumbai's high Covid count due to aggressive te...</td>\n",
              "      <td>&gt; high Covid count due to aggressive testing\\n...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Food</td>\n",
              "      <td>https://twitter.com/KeralaTourism/status/12174...</td>\n",
              "      <td>@KeralaTourism: Tender chunks of beef, slow-ro...</td>\n",
              "      <td>[removed]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sports</td>\n",
              "      <td>https://www-thehindu-com.cdn.ampproject.org/v/...</td>\n",
              "      <td>Music from the string quartet that raised the ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AMA</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/76xx01...</td>\n",
              "      <td>I am Ashish K. Mishra, I write stories. AMA</td>\n",
              "      <td>Would you rather reverse one decision you make...</td>\n",
              "      <td>I am the Managing Editor of The Ken. We write ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Flair  ...                                               Body\n",
              "0   [R]eddiquette  ...  A little long story.  I am going through a lot...\n",
              "1  Policy/Economy  ...                                                NaN\n",
              "2            Food  ...                                                NaN\n",
              "3          Sports  ...                                                NaN\n",
              "4             AMA  ...  I am the Managing Editor of The Ken. We write ...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbFcwdfItxac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "7d47e48e-5517-404e-dabe-2b284d849cb3"
      },
      "source": [
        "# Assigning and individual id to each flair\n",
        "data['id'] = data['Flair'].factorize()[0]\n",
        "flair_category = data[['Flair', 'id']].drop_duplicates().sort_values('id')\n",
        "flair_category"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Flair</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[R]eddiquette</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Policy/Economy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Food</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sports</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AMA</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Business/Finance</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Photography</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Science/Technology</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>AskIndia</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Non-Political</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Politics</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Flair  id\n",
              "0        [R]eddiquette   0\n",
              "1       Policy/Economy   1\n",
              "2                 Food   2\n",
              "3               Sports   3\n",
              "4                  AMA   4\n",
              "6     Business/Finance   5\n",
              "7          Photography   6\n",
              "12  Science/Technology   7\n",
              "20            AskIndia   8\n",
              "23       Non-Political   9\n",
              "24            Politics  10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCloknaBt5JW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "9a92e566-69a9-404b-f26b-8dfd3408369b"
      },
      "source": [
        "# Convert into a label dictionary \n",
        "category_labels = dict(flair_category.values)\n",
        "print(category_labels)\n",
        "\n",
        "print(\"=======\"*15) # Line break display\n",
        "\n",
        "# Similarly, we can create an inverse of the previous one to convert labels to categories\n",
        "category_reverse = dict(flair_category[['id', 'Flair']].values)\n",
        "print(category_reverse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'[R]eddiquette': 0, 'Policy/Economy': 1, 'Food': 2, 'Sports': 3, 'AMA': 4, 'Business/Finance': 5, 'Photography': 6, 'Science/Technology': 7, 'AskIndia': 8, 'Non-Political': 9, 'Politics': 10}\n",
            "=========================================================================================================\n",
            "{0: '[R]eddiquette', 1: 'Policy/Economy', 2: 'Food', 3: 'Sports', 4: 'AMA', 5: 'Business/Finance', 6: 'Photography', 7: 'Science/Technology', 8: 'AskIndia', 9: 'Non-Political', 10: 'Politics'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70A5jlzkuCx2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cec8badb-87d5-4ead-c770-6a0543527b73"
      },
      "source": [
        "data['Combine'] = data['Title'] # Create a column combined\n",
        "count = 0\n",
        "for i in range(len(data)):\n",
        "    if type(data.loc[i]['Body']) != float:\n",
        "        data['Combine'][i] = data['Combine'][i] + ' ' + data['Body'][i]\n",
        "\n",
        "    if type(data.loc[i]['Comments']) != float:\n",
        "        data['Combine'][i] = data['Combine'][i] + ' ' + data['Comments'][i]\n",
        "\n",
        "data.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Flair</th>\n",
              "      <th>URL</th>\n",
              "      <th>Title</th>\n",
              "      <th>Comments</th>\n",
              "      <th>Body</th>\n",
              "      <th>id</th>\n",
              "      <th>Combine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[R]eddiquette</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/d0em6s...</td>\n",
              "      <td>I finally convinced him. That awesome moment w...</td>\n",
              "      <td>Larke ko ias officer banao....kudos to you op.</td>\n",
              "      <td>A little long story.  I am going through a lot...</td>\n",
              "      <td>0</td>\n",
              "      <td>I finally convinced him. That awesome moment w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Policy/Economy</td>\n",
              "      <td>https://theprint.in/theprint-otc/mumbais-high-...</td>\n",
              "      <td>Mumbai's high Covid count due to aggressive te...</td>\n",
              "      <td>&gt; high Covid count due to aggressive testing\\n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>Mumbai's high Covid count due to aggressive te...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Food</td>\n",
              "      <td>https://twitter.com/KeralaTourism/status/12174...</td>\n",
              "      <td>@KeralaTourism: Tender chunks of beef, slow-ro...</td>\n",
              "      <td>[removed]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>@KeralaTourism: Tender chunks of beef, slow-ro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sports</td>\n",
              "      <td>https://www-thehindu-com.cdn.ampproject.org/v/...</td>\n",
              "      <td>Music from the string quartet that raised the ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Music from the string quartet that raised the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AMA</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/76xx01...</td>\n",
              "      <td>I am Ashish K. Mishra, I write stories. AMA</td>\n",
              "      <td>Would you rather reverse one decision you make...</td>\n",
              "      <td>I am the Managing Editor of The Ken. We write ...</td>\n",
              "      <td>4</td>\n",
              "      <td>I am Ashish K. Mishra, I write stories. AMA I ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Sports</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/f5pxap...</td>\n",
              "      <td>Need help related to my research project on Sp...</td>\n",
              "      <td>Filled it</td>\n",
              "      <td>Hey guys,\\n\\nI am working on a research projec...</td>\n",
              "      <td>3</td>\n",
              "      <td>Need help related to my research project on Sp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Business/Finance</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/g0zm53...</td>\n",
              "      <td>The Current scenario for IT professionals (Cov...</td>\n",
              "      <td>I work for an OTT client, so their business is...</td>\n",
              "      <td>Hey guys, i wanted to know what's the scenario...</td>\n",
              "      <td>5</td>\n",
              "      <td>The Current scenario for IT professionals (Cov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Photography</td>\n",
              "      <td>https://i.redd.it/zrdg4z3wbjr31.jpg</td>\n",
              "      <td>Kolkata at night during Durga Pujo</td>\n",
              "      <td>Fuck that pollution looks like hell.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "      <td>Kolkata at night during Durga Pujo Fuck that p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Photography</td>\n",
              "      <td>https://i.redd.it/rphk0n2proa41.jpg</td>\n",
              "      <td>Everybody's posting pictures of my hometown, s...</td>\n",
              "      <td>And here i am waiting for vikendi update</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "      <td>Everybody's posting pictures of my hometown, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>AMA</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/35eabh...</td>\n",
              "      <td>Hello Reddit! Kaneez Surka here. Ask Me Anythi...</td>\n",
              "      <td>Unlike Aditi Mittal, can we find hot pics of y...</td>\n",
              "      <td>I am a comedian and improviser. Currently part...</td>\n",
              "      <td>4</td>\n",
              "      <td>Hello Reddit! Kaneez Surka here. Ask Me Anythi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Photography</td>\n",
              "      <td>https://youtu.be/qRyOv-HDGCY</td>\n",
              "      <td>Wagle Ki Duniya</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "      <td>Wagle Ki Duniya</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Business/Finance</td>\n",
              "      <td>https://theprint.in/india/probe-finds-rs-2000-...</td>\n",
              "      <td>Probe finds Rs 2,000 crore missing at Café Cof...</td>\n",
              "      <td>Good to know.. Now how about telling us how mi...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>Probe finds Rs 2,000 crore missing at Café Cof...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Science/Technology</td>\n",
              "      <td>http://www.mydigitalstartup.net/2020/04/20/gov...</td>\n",
              "      <td>Indian Government's Video Conferencing Solutio...</td>\n",
              "      <td>We got hangouts meet, discord, Skype .\\nDon't ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7</td>\n",
              "      <td>Indian Government's Video Conferencing Solutio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>AMA</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/46drra...</td>\n",
              "      <td>I am Pranav Dixit, Technology Editor at Hindus...</td>\n",
              "      <td>Climate change is a threat which affects us al...</td>\n",
              "      <td>Update: OK, I think I've answered most questio...</td>\n",
              "      <td>4</td>\n",
              "      <td>I am Pranav Dixit, Technology Editor at Hindus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Business/Finance</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/g3j2q4...</td>\n",
              "      <td>Joining Choices</td>\n",
              "      <td>Are you trying to show off?  Becoz proud and p...</td>\n",
              "      <td>Okay, here goes my first reddit post\\n\\nI , a ...</td>\n",
              "      <td>5</td>\n",
              "      <td>Joining Choices Okay, here goes my first reddi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Policy/Economy</td>\n",
              "      <td>https://www.thehindubusinessline.com/info-tech...</td>\n",
              "      <td>How China dominates tech investments in India</td>\n",
              "      <td>Well India has nukes, India can negotiate bett...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>How China dominates tech investments in India ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Policy/Economy</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/funp0c...</td>\n",
              "      <td>We are facing one of the most challenging time...</td>\n",
              "      <td>Neither Trump nor the political masters of our...</td>\n",
              "      <td>There is a global crises of leadership. Under ...</td>\n",
              "      <td>1</td>\n",
              "      <td>We are facing one of the most challenging time...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Photography</td>\n",
              "      <td>https://imgur.com/as9nBcw</td>\n",
              "      <td>Torna Fort, Pune [Ascended from South Budhla M...</td>\n",
              "      <td>Mark it OC</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "      <td>Torna Fort, Pune [Ascended from South Budhla M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Food</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/g07a97...</td>\n",
              "      <td>Do Indian restaurants actually use yeast to le...</td>\n",
              "      <td>Yeah i think so, also do you leave it after kn...</td>\n",
              "      <td>Short version:\\n\\nA  naan's crumb  seems to be...</td>\n",
              "      <td>2</td>\n",
              "      <td>Do Indian restaurants actually use yeast to le...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Food</td>\n",
              "      <td>https://economictimes.indiatimes.com/news/poli...</td>\n",
              "      <td>Thousands of litres of cow urine consumed in G...</td>\n",
              "      <td>people who do this should be denied scientific...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>Thousands of litres of cow urine consumed in G...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Flair  ...                                            Combine\n",
              "0        [R]eddiquette  ...  I finally convinced him. That awesome moment w...\n",
              "1       Policy/Economy  ...  Mumbai's high Covid count due to aggressive te...\n",
              "2                 Food  ...  @KeralaTourism: Tender chunks of beef, slow-ro...\n",
              "3               Sports  ...  Music from the string quartet that raised the ...\n",
              "4                  AMA  ...  I am Ashish K. Mishra, I write stories. AMA I ...\n",
              "5               Sports  ...  Need help related to my research project on Sp...\n",
              "6     Business/Finance  ...  The Current scenario for IT professionals (Cov...\n",
              "7          Photography  ...  Kolkata at night during Durga Pujo Fuck that p...\n",
              "8          Photography  ...  Everybody's posting pictures of my hometown, s...\n",
              "9                  AMA  ...  Hello Reddit! Kaneez Surka here. Ask Me Anythi...\n",
              "10         Photography  ...                                    Wagle Ki Duniya\n",
              "11    Business/Finance  ...  Probe finds Rs 2,000 crore missing at Café Cof...\n",
              "12  Science/Technology  ...  Indian Government's Video Conferencing Solutio...\n",
              "13                 AMA  ...  I am Pranav Dixit, Technology Editor at Hindus...\n",
              "14    Business/Finance  ...  Joining Choices Okay, here goes my first reddi...\n",
              "15      Policy/Economy  ...  How China dominates tech investments in India ...\n",
              "16      Policy/Economy  ...  We are facing one of the most challenging time...\n",
              "17         Photography  ...  Torna Fort, Pune [Ascended from South Budhla M...\n",
              "18                Food  ...  Do Indian restaurants actually use yeast to le...\n",
              "19                Food  ...  Thousands of litres of cow urine consumed in G...\n",
              "\n",
              "[20 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC0fNq5iuVZp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "ece9eb0b-7b30-4742-e26d-f64503057b62"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Collect all the english stopwords and display them\n",
        "STOPWORDS = nltk.corpus.stopwords.words('english')\n",
        "print(STOPWORDS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmbqXhgpuguO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "742a12d8-1f75-4aa7-a3ad-831a78f11490"
      },
      "source": [
        "REPLACE_SPACES = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS = re.compile('[^0-9a-z #+_]')\n",
        "\n",
        "def clean_text(text):\n",
        "    '''\n",
        "        text: a string\n",
        "        return: modified initial string\n",
        "    '''\n",
        "\n",
        "    text = text.lower() # lowercase text\n",
        "    text = REPLACE_SPACES.sub(' ', text) \n",
        "    text = BAD_SYMBOLS.sub('', text) # Replace Bad Symbols which \n",
        "    text = text.replace('x', '')\n",
        "    \n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
        "    return text\n",
        "\n",
        "data['Combine'] = data['Combine'].apply(clean_text)\n",
        "data['Combine'] = data['Combine'].str.replace('\\d+', '')\n",
        "data['Combine'].head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    finally convinced awesome moment understand es...\n",
              "1    mumbais high covid count due aggressive testin...\n",
              "2    keralatourism tender chunks beef slowroasted a...\n",
              "3     music string quartet raised level indian cricket\n",
              "4    ashish k mishra write stories ama managing edi...\n",
              "5    need help related research project sports cons...\n",
              "6    current scenario professionals covid hey guys ...\n",
              "7    kolkata night durga pujo fuck pollution looks ...\n",
              "8    everybodys posting pictures hometown figured i...\n",
              "9    hello reddit kaneez surka ask anything comedia...\n",
              "Name: Combine, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD8YscUXusK-"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2C6ICkVu2_r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f3a0c0f4-84a1-4e94-8ef6-b1afa84e4f31"
      },
      "source": [
        "# Creating an instance of the Tfidf vectorizer\n",
        "tfidf = TfidfVectorizer(sublinear_tf=True, \n",
        "                        min_df=5, \n",
        "                        norm = 'l2', \n",
        "                        encoding='latin-1', \n",
        "                        ngram_range=(1, 2))\n",
        "\n",
        "\n",
        "# Extracting the features by fitting the Vectorizer on Combined Data\n",
        "feat = tfidf.fit_transform(data['Combine']).toarray()\n",
        "labels = data['id']    # Series containing all the post labels\n",
        "print(feat.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1650, 3299)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zFRkZ1ku6PS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa9f8165-6d66-4239-bc54-6d9f15fe89d8"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data['Combine'], data['Flair'], \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state=42)\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1320,) (1320,) (330,) (330,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msZhLH-4vDtt"
      },
      "source": [
        "# Creating an instance of the TFID transformer\n",
        "count_vec = CountVectorizer()\n",
        "X_train_counts = count_vec.fit_transform(X_train)\n",
        "\n",
        "# Creating an instance of the TFID transformer\n",
        "tfidf_trans = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_trans.fit_transform(X_train_counts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVWc49TxxPm9"
      },
      "source": [
        "X_test_counts = count_vec.transform(X_test)\n",
        "X_test_tfidf = tfidf_trans.transform(X_test_counts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIl1Gr-5vIrI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0993c970-3b0a-49e9-c002-34e92f12dafe"
      },
      "source": [
        "# Create an instance \n",
        "model = MultinomialNB()\n",
        "# Fit to training data\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "# Predictions on X_test_tfidf\n",
        "# Obtain X_test_tfidf in the manner described above\n",
        "model.predict(X_test_tfidf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['AMA', 'Policy/Economy', 'Policy/Economy', '[R]eddiquette',\n",
              "       'Policy/Economy', 'Business/Finance', 'AMA', 'AMA', 'AskIndia',\n",
              "       'Policy/Economy', 'AskIndia', 'Policy/Economy', 'Food',\n",
              "       'Photography', 'AskIndia', 'AMA', 'Policy/Economy', 'Photography',\n",
              "       'AskIndia', 'Sports', 'AskIndia', 'Food', 'AMA', 'AskIndia', 'AMA',\n",
              "       'Policy/Economy', 'AskIndia', 'AskIndia', 'Sports', 'AMA',\n",
              "       'AskIndia', 'Policy/Economy', 'AskIndia', 'AskIndia', 'AMA',\n",
              "       'Food', 'Photography', 'Business/Finance', 'Politics', 'Politics',\n",
              "       'Politics', 'AMA', 'AMA', 'AskIndia', 'AskIndia', 'Photography',\n",
              "       'AMA', 'Sports', 'Sports', 'Politics', 'AMA', 'Photography',\n",
              "       'Sports', 'AskIndia', 'AskIndia', 'Politics', 'Food',\n",
              "       'Business/Finance', 'Sports', 'AMA', 'AMA', 'AMA', 'Sports',\n",
              "       'Sports', 'AskIndia', 'AMA', 'AskIndia', 'Non-Political',\n",
              "       'Business/Finance', 'AskIndia', 'AskIndia', 'AskIndia',\n",
              "       'Business/Finance', 'AskIndia', 'AskIndia', 'Business/Finance',\n",
              "       'AskIndia', 'AMA', 'Sports', 'AskIndia', 'Photography',\n",
              "       'Photography', 'Business/Finance', 'AskIndia', 'Photography',\n",
              "       'AskIndia', 'Photography', 'Policy/Economy', 'Business/Finance',\n",
              "       'AskIndia', 'Policy/Economy', 'AMA', 'Photography',\n",
              "       'Policy/Economy', 'AMA', 'Science/Technology', 'Politics',\n",
              "       '[R]eddiquette', 'Business/Finance', 'AskIndia',\n",
              "       'Business/Finance', 'Photography', 'Non-Political', 'AskIndia',\n",
              "       'AskIndia', 'Non-Political', 'AMA', 'Science/Technology',\n",
              "       'Policy/Economy', 'AskIndia', 'AskIndia', 'AskIndia', 'AskIndia',\n",
              "       'AMA', 'AskIndia', '[R]eddiquette', 'Business/Finance', 'AskIndia',\n",
              "       'AskIndia', 'Sports', 'Politics', 'AskIndia', 'Sports', 'AskIndia',\n",
              "       'Photography', 'AskIndia', 'Business/Finance', 'Politics',\n",
              "       'Policy/Economy', 'Photography', 'AskIndia', '[R]eddiquette',\n",
              "       'AskIndia', 'AskIndia', 'AskIndia', 'AMA', 'Politics', 'AMA',\n",
              "       'AskIndia', 'AskIndia', 'Policy/Economy', 'Policy/Economy', 'AMA',\n",
              "       'AskIndia', 'AskIndia', 'Policy/Economy', 'AskIndia',\n",
              "       'Science/Technology', 'Photography', 'Business/Finance',\n",
              "       'AskIndia', 'Politics', 'AskIndia', 'AskIndia', 'Business/Finance',\n",
              "       'AskIndia', 'AskIndia', 'AskIndia', 'AMA', 'Policy/Economy',\n",
              "       'Business/Finance', 'Photography', 'Policy/Economy', 'AMA',\n",
              "       'Politics', 'AskIndia', 'AskIndia', 'Policy/Economy', 'AskIndia',\n",
              "       'Politics', 'AMA', 'Politics', 'AskIndia', 'AskIndia', 'Food',\n",
              "       'Business/Finance', 'AskIndia', 'AskIndia', 'Policy/Economy',\n",
              "       'Food', 'AMA', 'AskIndia', 'Policy/Economy', 'Policy/Economy',\n",
              "       'Politics', 'Food', 'AskIndia', '[R]eddiquette', 'Photography',\n",
              "       'AMA', '[R]eddiquette', 'AskIndia', 'Science/Technology',\n",
              "       'Non-Political', 'Photography', '[R]eddiquette', 'AskIndia',\n",
              "       'AskIndia', 'Photography', 'Policy/Economy', 'Food', 'Photography',\n",
              "       'AskIndia', 'AskIndia', 'Food', 'Science/Technology', 'Sports',\n",
              "       'Non-Political', 'Photography', 'AskIndia', 'AskIndia', 'AskIndia',\n",
              "       'AskIndia', 'AMA', 'AskIndia', 'Photography', 'Photography',\n",
              "       'Sports', 'Sports', 'Photography', 'Business/Finance', 'AMA',\n",
              "       'Policy/Economy', 'Policy/Economy', 'AskIndia', '[R]eddiquette',\n",
              "       'AMA', 'Food', 'Business/Finance', 'Sports', 'AskIndia', 'Food',\n",
              "       'AskIndia', 'Policy/Economy', 'AskIndia', 'AMA', 'AMA', 'AskIndia',\n",
              "       'Policy/Economy', 'Sports', 'AskIndia', '[R]eddiquette',\n",
              "       'AskIndia', 'AskIndia', 'Sports', 'Politics', 'AskIndia',\n",
              "       'Science/Technology', 'Policy/Economy', 'AMA', 'AskIndia',\n",
              "       'Business/Finance', 'Photography', 'AskIndia', 'AMA',\n",
              "       '[R]eddiquette', 'AskIndia', 'AMA', 'Policy/Economy', 'AMA',\n",
              "       '[R]eddiquette', 'Photography', 'Policy/Economy', 'AskIndia',\n",
              "       'AskIndia', 'AskIndia', '[R]eddiquette', 'Politics', 'AskIndia',\n",
              "       'AMA', 'AskIndia', 'Policy/Economy', 'Politics', 'AskIndia',\n",
              "       'Photography', 'AskIndia', 'Policy/Economy', 'Food', 'AMA',\n",
              "       'Non-Political', 'AskIndia', '[R]eddiquette', 'AskIndia',\n",
              "       'Photography', 'AskIndia', 'Politics', 'Food', '[R]eddiquette',\n",
              "       'AMA', 'Business/Finance', 'Business/Finance', 'AMA',\n",
              "       'Science/Technology', 'AskIndia', 'Policy/Economy', 'AskIndia',\n",
              "       'Food', 'Food', 'Photography', 'AskIndia', 'AskIndia',\n",
              "       'Policy/Economy', 'AskIndia', 'Politics', 'Non-Political', 'Food',\n",
              "       '[R]eddiquette', 'AskIndia', 'AskIndia', 'AskIndia', 'AMA',\n",
              "       'Policy/Economy', 'Business/Finance', 'AskIndia', 'AMA',\n",
              "       'AskIndia', 'Politics', 'Politics', 'AMA', 'Business/Finance',\n",
              "       'AMA', 'AMA', 'Business/Finance', 'AMA', 'AMA', 'Policy/Economy',\n",
              "       'AskIndia', 'Policy/Economy', 'AskIndia', 'Policy/Economy'],\n",
              "      dtype='<U18')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EG9xOXF0vPEl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "83fd6b57-f6c7-4077-9efa-575e00b2e12b"
      },
      "source": [
        "X_train_tfidf.todense()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un8N5qnuxXAZ"
      },
      "source": [
        "nb_fit = Pipeline([('vect', CountVectorizer()),\n",
        "                   ('tfidf', TfidfTransformer()),\n",
        "                   ('clf', MultinomialNB())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo-1nFeQx8mR"
      },
      "source": [
        "# Naive Bayes Classifier \n",
        "def nb_classifier(X_train, X_test, y_train, y_test):\n",
        "    \n",
        "    nb_fit = Pipeline([('vect', CountVectorizer()),\n",
        "                  ('tfidf', TfidfTransformer()),\n",
        "                  ('model', MultinomialNB()),\n",
        "                 ])\n",
        "    nb_fit.fit(X_train, y_train)    # Fitting the data to the trianing data\n",
        "    \n",
        "    # Making Predictions on the test data\n",
        "    y_pred = nb_fit.predict(X_test)\n",
        "    acc = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
        "    print(\"Model Accuracy: {}\".format(acc))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SybSrUXKyEAW"
      },
      "source": [
        "# Random Forest Classifier\n",
        "def random_forest(X_train, X_test, y_train, y_test):\n",
        "    \n",
        "    forest = Pipeline([('vect', CountVectorizer()),\n",
        "                  ('tfidf', TfidfTransformer()),\n",
        "                  ('model', RandomForestClassifier()),\n",
        "                 ])\n",
        "    forest.fit(X_train, y_train)    # Fitting the data to the trianing data\n",
        "    \n",
        "    # Making Predictions on the test data\n",
        "    y_pred = forest.predict(X_test)\n",
        "    acc = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
        "    print(\"Model Accuracy: {}\".format(acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pECKP8LhyIOf"
      },
      "source": [
        "# Support Vector Machines Classifier \n",
        "def svc(X_train, X_test, y_train, y_test):\n",
        "    \n",
        "    svc_fit = Pipeline([('vect', CountVectorizer()),\n",
        "                  ('tfidf', TfidfTransformer()),\n",
        "                  ('model', SVC()),\n",
        "                 ])\n",
        "    svc_fit.fit(X_train, y_train)    # Fitting the data to the trianing data\n",
        "    \n",
        "    # Making Predictions on the test data\n",
        "    y_pred = svc_fit.predict(X_test)\n",
        "    acc = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
        "    print(\"Model Accuracy: {}\".format(acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDsk-2ILyKUc"
      },
      "source": [
        "# Logistic Regression Classifier \n",
        "def log_reg(X_train, X_test, y_train, y_test):\n",
        "    \n",
        "    logreg = Pipeline([('vect', CountVectorizer()),\n",
        "                  ('tfidf', TfidfTransformer()),\n",
        "                  ('model', LogisticRegression()),\n",
        "                 ])\n",
        "    logreg.fit(X_train, y_train)     # Fitting the data to the trianing data\n",
        "\n",
        "    # Making Predictions on the test data\n",
        "    y_pred = logreg.predict(X_test)\n",
        "    acc = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
        "    print(\"Model Accuracy: {}\".format(acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wkygorWyjHH"
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6V8oe2WyMqp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f80e399b-526d-45ac-a1ee-e361601331f8"
      },
      "source": [
        "print(\"Evaluate Naive Bayes Classifier\")\n",
        "nb_classifier(X_train, X_test, y_train, y_test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluate Naive Bayes Classifier\n",
            "Model Accuracy: 0.49393939393939396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI6egzt2yTZj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6ca63983-ec21-4402-8f49-c7b8886e87c2"
      },
      "source": [
        "print(\"Evaluate Random Forest Classifier\")\n",
        "random_forest(X_train, X_test, y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluate Random Forest Classifier\n",
            "Model Accuracy: 0.5151515151515151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBEN1xXhyWcm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bb51d995-39c3-4c47-ea1c-35fbe9d21741"
      },
      "source": [
        "print(\"Evaluate Logistic Regression Model\")\n",
        "log_reg(X_train, X_test, y_train, y_test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluate Logistic Regression Model\n",
            "Model Accuracy: 0.5848484848484848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufrbPGtByX8r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2f8c8f37-a502-4a02-a8ca-d509246b2a1c"
      },
      "source": [
        "print(\"Evaluate SVC Model\")\n",
        "svc(X_train, X_test, y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluate SVC Model\n",
            "Model Accuracy: 0.5484848484848485\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}